{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Chatbot"
      ],
      "metadata": {
        "id": "hHYg6kZvaZ2C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Importing the Libraries"
      ],
      "metadata": {
        "id": "eM2WHeLYaUtk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "dXYI826oZkP_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import nltk\n",
        "import string\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Reading the Corpus of Text"
      ],
      "metadata": {
        "id": "noHlFRDdrCov"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f = open('/content/data.txt','r',errors = 'ignore')\n",
        "raw_doc = f.read()"
      ],
      "metadata": {
        "id": "R5FILGPqafPI"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_doc = raw_doc.lower() #Converting entire text to lowercase\n",
        "nltk.download('punkt') #Using the Punkt tonkenizer\n",
        "nltk.download('wordnet') #Using the wordnet dictionary\n",
        "nltk.download('omw-1.4') # Downloads the Open Multilingual WordNet 1.4 dataset from NLTK's data repository."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jd1Fkb25sWM4",
        "outputId": "d8ad3a95-d713-4228-a661-347519b49dfa"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_tokens = nltk.sent_tokenize(raw_doc) # Splits the raw document into individual sentences.\n",
        "word_tokens = nltk.word_tokenize(raw_doc)  # Splits the raw document into individual words."
      ],
      "metadata": {
        "id": "6ynXUWZ0uqp7"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##After Tokenization"
      ],
      "metadata": {
        "id": "X4s4wd0Ouul-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_tokens[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpZhOX87utqr",
        "outputId": "13abc34c-86a2-46cd-a268-9a9316772ef7"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hi, how are you doing?',\n",
              " \"i'm fine.\",\n",
              " 'how about yourself?',\n",
              " \"i'm fine.\",\n",
              " 'how about yourself?']"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_tokens[:5]"
      ],
      "metadata": {
        "id": "CJfPJhEJvdwd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a8f724e-38ac-4ff6-d6b9-1e27c1a9efe5"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hi', ',', 'how', 'are', 'you']"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Performing Text-PreProcessing Steps\n"
      ],
      "metadata": {
        "id": "CvgkJlF5k2GX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lemmer = nltk.stem.WordNetLemmatizer()                                          # Creates a WordNetLemmatizer object to reduce words to their base form.\n",
        "def LemTokens (tokens):                                                         # Function to lemmatize a list of tokens.\n",
        "  return [lemmer.lemmatize(token) for token in tokens]\n",
        "remove_punc_dict= dict((ord(punct), None) for punct in string.punctuation)      # Creates a dictionary to remove punctuation from text.\n",
        "def LemNormalize(text):                                                         # Function to normalize text by converting to lowercase, removing punctuation, and lemmatizing.\n",
        "  return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punc_dict)))"
      ],
      "metadata": {
        "id": "uNjEfNfJcp4F"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Define Greeting functions\n"
      ],
      "metadata": {
        "id": "yRqAlxWFlZ3C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "greet_inputs = ('hello', 'hi', 'whassup', 'how are you?')                  # List of possible greetings from the user.\n",
        "greet_responses = ('hi', 'Hey', 'Hey There!', 'There there!!')             # List of possible responses to greetings.\n",
        "def greet(sentence):                                                       # Function to respond to a user's greeting.\n",
        "  for word in sentence.split():\n",
        "    if word.lower() in greet_inputs:\n",
        "      return random.choice(greet_responses)                                # Returns a random response if the user's sentence contains a greeting."
      ],
      "metadata": {
        "id": "RlzbpuPulbCh"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Response Generation by the Bot\n"
      ],
      "metadata": {
        "id": "DKGfZgxGlhdN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer  # Imports a module to convert text data into a matrix of TF-IDF features.\n",
        "from sklearn.metrics.pairwise import cosine_similarity        # Imports a function to calculate the cosine similarity between vectors."
      ],
      "metadata": {
        "id": "TJXIKVVilj0U"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def response(user_response):         # Function to generate a response from the chatbot based on the user's input using TF-IDF vectorization and cosine similarity.\n",
        "  robo1_response = ''                                 # Initializes an empty string to store the chatbot's response.\n",
        "  TfidfVec = TfidfVectorizer(tokenizer = LemNormalize, stop_words = 'english', token_pattern = None)\n",
        "  tfidf = TfidfVec.fit_transform(sentence_tokens)                               # Converts the sentence tokens into a TF-IDF matrix.\n",
        "  vals = cosine_similarity(tfidf[-1], tfidf)                                    # Calculates the cosine similarity between the last sentence in the matrix and all other sentences.\n",
        "  idx = vals.argsort()[0][-2]                                                   # Gets the index of the second-highest similarity score.\n",
        "  flat = vals.flatten()                                                         # Flattens the similarity scores into a 1D array.\n",
        "  flat.sort()                                                                   # Sorts the flattened array in ascending order.\n",
        "  req_tfidf = flat[-2]                                                          # Gets the second-highest similarity score.\n",
        "  if (req_tfidf == 0):                                                          # Checks if the second-highest similarity score is zero.\n",
        "    robo1_response = robo1_response + \"I am sorry. Unable to understand you!\"   # If the score is zero, the chatbot responds with an appropriate message.\n",
        "    return robo1_response                                                      # Returns the chatbot's response.\n",
        "  else:                                                                         # If the score is not zero, the chatbot responds with the second-highest similarity sentence.\n",
        "    robo1_response = robo1_response + sentence_tokens[idx]\n",
        "    return robo1_response                                                      # Returns the chatbot's response."
      ],
      "metadata": {
        "id": "EZmZ15Wdl7WO"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Defining the ChatFlow"
      ],
      "metadata": {
        "id": "d4fj-U1Hm7Sh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "flag = True                                                             # Initializes a flag variable to True\n",
        "print('Hello! I am the Retreival Learning Bot. Start typing your text after greeting to talk to me. For ending convo type bye!') # Prints a greeting message\n",
        "while(flag == True):                                                    # Starts a while loop to continue the conversation until the flag is set to False\n",
        "  user_response = input()                                                # Takes input from the user\n",
        "  user_response = user_response.lower()                                  # Converts the user's input to lowercase\n",
        "  if(user_response != 'bye'):                                            # Checks if the user's input is not 'bye'\n",
        "    if(user_response == 'thank you' or user_response == 'thanks'):       # Checks if the user's input is 'thank you' or 'thanks'\n",
        "      flag = False                                                      # Sets the flag to False to end the conversation\n",
        "      print('Bot: You are Welcome..')                                  # Prints a response\n",
        "    else:                                                              # If the user's input is not 'thank you' or 'thanks'\n",
        "      if(greet(user_response) != None):                                 # Checks if the user's input is a greeting\n",
        "        print('Bot '+ greet(user_response))                              # Prints the response to the greeting\n",
        "      else:\n",
        "        sentence_tokens.append(user_response)                             # Appends the user's input to the sentence tokens\n",
        "        word_tokens = word_tokens + nltk.word_tokenize(user_response)\n",
        "        final_words = list(set(word_tokens))\n",
        "        print('Bot: ', end = '')                                           # Prints a response\n",
        "        print(response(user_response))                                     # Prints the response to the user's input\n",
        "        sentence_tokens.remove(user_response)                              # Removes the user's input from the sentence tokens\n",
        "  else:                                                                  # If the user's input is 'bye'\n",
        "    flag = False                                                          # Sets the flag to False to end the conversation\n",
        "    print('Bot: Goodbye!')                                                    # Prints a goodbye message"
      ],
      "metadata": {
        "id": "9hWDD7nnm-qK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}